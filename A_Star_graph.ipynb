{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import queue\n",
    "from typing import *\n",
    "import typing\n",
    "import numpy\n",
    "import agent\n",
    "import copy\n",
    "\n",
    "import os, psutil\n",
    "import resource \n",
    "\n",
    "import environment \n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class A_Star_Search():\n",
    "\n",
    "    ###\n",
    "    # find coordinate of a tile given its hash\n",
    "    # \n",
    "    # input: \n",
    "    #   env: numpy matrix of 8 digit hash values\n",
    "    #   hash_value: 8 digit hash of str(coordinate of tile)\n",
    "    # output:\n",
    "    #   [x,y] coordinates\n",
    "    # \n",
    "    # ###\n",
    "    def find_tile_by_hash(self, env: environment.Environment, hash_value: int):\n",
    "        x_coord, y_coord = numpy.where(env.get_environment_hash_matrix()[:,:] == hash_value)\n",
    "        return [x_coord[0], y_coord[0]]\n",
    "    \n",
    "    ###\n",
    "    # find list tiles accessible from current position (not obstacles)\n",
    "    # update agent's moves possibilities\n",
    "    # input:\n",
    "    #       node_list_coord_hash: 8 digit hash of str(coordinate of tile)  \n",
    "    #       env: numpy matrix of 8 digit hash values \n",
    "    #       closed_set: seen nodes\n",
    "    #       agent: current agent   \n",
    "    # output:\n",
    "    #       children_list: list of 8 digit hash values accessible from current position\n",
    "    #       agent: updated agent\n",
    "    ####\n",
    "    def generate_children_list(self, node_list_coord_hash: int, env: environment.Environment, closed_set: List[int] ,agent: agent.Agent):\n",
    "        current_node_coord_list = self.find_tile_by_hash(env, node_list_coord_hash)\n",
    "        node_x_axis = current_node_coord_list[0] \n",
    "        node_y_axis = current_node_coord_list[1]\n",
    "        children_list = []\n",
    "        moves_list = []#empty list\n",
    "        agent_motion_cost = agent.get_motion_cost()\n",
    "\n",
    "        ###### UPDATE AGENT MOVES POSSIBLITIES  \n",
    "        #can agent go up ?\n",
    "        if node_x_axis-1 >= 0:\n",
    "            child_hash = env.get_environment_hash_matrix()[node_x_axis-1, node_y_axis]\n",
    "\n",
    "            tile_is_obstacle = env.get_environment_matrix()[node_x_axis-1, node_y_axis]\n",
    "            if(tile_is_obstacle == 0) and child_hash not in closed_set:#if tile is not obstacle\n",
    "                children_list.append((agent_motion_cost[0] , child_hash))\n",
    "                moves_list.append(\"U\")\n",
    "\n",
    "        # can agent go right ?\n",
    "        if node_y_axis+1 < env.get_matrix_dimension()[1]:\n",
    "            child_hash = env.get_environment_hash_matrix()[ node_x_axis, node_y_axis+1] \n",
    "            tile_is_obstacle = env.get_environment_matrix()[node_x_axis, node_y_axis+1]\n",
    "            if(tile_is_obstacle == 0) and child_hash not in closed_set:#if tile is not obstacle\n",
    "                children_list.append((agent_motion_cost[3] , child_hash))\n",
    "                moves_list.append(\"R\")\n",
    "\n",
    "        # can agent go down ?\n",
    "        if node_x_axis+1 < env.get_matrix_dimension()[0]: \n",
    "            child_hash = env.get_environment_hash_matrix()[node_x_axis+1, node_y_axis]\n",
    "            tile_is_obstacle = env.get_environment_matrix()[node_x_axis+1, node_y_axis]\n",
    "\n",
    "            if(tile_is_obstacle == 0) and child_hash not in closed_set:#if tile is not obstacle\n",
    "                children_list.append((agent_motion_cost[1] , child_hash))\n",
    "                moves_list.append(\"D\")\n",
    "        \n",
    "            # can agent go left ?\n",
    "        if node_y_axis-1 >= 0:\n",
    "            child_hash = env.get_environment_hash_matrix()[ node_x_axis, node_y_axis-1] \n",
    "            tile_is_obstacle = env.get_environment_matrix()[node_x_axis, node_y_axis-1]\n",
    "            if(tile_is_obstacle == 0) and child_hash not in closed_set:#if tile is not obstacle\n",
    "                children_list.append((agent_motion_cost[2] , child_hash))\n",
    "                moves_list.append(\"L\")\n",
    "\n",
    "        agent.moves_list = moves_list # update agent list\n",
    "        return children_list, agent\n",
    "\n",
    "\n",
    "    ###\n",
    "    # find goal tile\n",
    "    # \n",
    "    # input:\n",
    "    #       initial_state: 8 digit float of start state coord str([x,y])  \n",
    "    #       goal_state: 8 digit float of goal state coord str([x,y])\n",
    "    #       my_plt: plot obj\n",
    "    #  output: \n",
    "    #       parent: goal node ((cost, g+h), (hash_of_node, hash_of_parent))\n",
    "    #       edges_dict: all node ever placed in priority queue\n",
    "    #       memoized_costs: memoized cost of every explored node\n",
    "    # ###\n",
    "    def fetch_Goal_Node(self, \n",
    "    intial_state: int, goal_state: int, queue_size, env_matrix, agent: agent.Agent):\n",
    "        init_s_node_hash = intial_state\n",
    "        goal_state_hash = goal_state\n",
    "        edges_dict = {}\n",
    "        memoized_costs = {}\n",
    "        goal_coord = self.find_tile_by_hash(env_matrix, goal_state_hash)\n",
    "        \n",
    "        pop_side = 0\n",
    "\n",
    "\n",
    "        open_set = []#unexplored nodes (contains only hashes) sorted by node cost, with priority1 < priority_x < prioty_n\n",
    "        open_set.append((0, init_s_node_hash))#populate first node\n",
    "        \n",
    "\n",
    "        closed_set = []\n",
    "        memoized_costs[init_s_node_hash]=0#initial cost\n",
    "        while open_set:\n",
    "\n",
    "            open_set = sorted(open_set, key=lambda tup: tup[0]) #sort by cost best cost on top\n",
    "\n",
    "            parent = open_set[pop_side]\n",
    "\n",
    "            if parent[1] == goal_state_hash:\n",
    "\n",
    "                return (parent[1], edges_dict, memoized_costs)  \n",
    "\n",
    "            open_set.remove(parent) #pop current (cost, state)  \n",
    "\n",
    "            closed_set.append(parent[1])#and appends to seen nodes\n",
    "\n",
    "            children_hash_list, updated_agent = self.generate_children_list(parent[1], env_matrix, closed_set , agent)\n",
    "\n",
    "            motion_cost_set = updated_agent.get_motion_cost()\n",
    "\n",
    "            parent_cost = memoized_costs[parent[1]]\n",
    "            move_option = 0 #keep track of direction index of move in agent current move set\n",
    "            \n",
    "            #print current expanding node\n",
    "            parent_coord = self.find_tile_by_hash(env_matrix ,parent[1])\n",
    "            my_plt.scatter(parent_coord[1], parent_coord[0], s=150, c='black', marker='s')\n",
    "            \n",
    "\n",
    "            for child_hash in children_hash_list:\n",
    "                                 \n",
    "                new_child = child_hash ##hash (state coordinate)\n",
    "                child_hash_value = child_hash[1]\n",
    "\n",
    "                current_child_cost = new_child[0]\n",
    "                current_child_coord = self.find_tile_by_hash(env_matrix ,child_hash_value)\n",
    "                manhatthan_dist = self.heuristic(current_child_coord, goal_coord)\n",
    "                \n",
    "                #if hash of new child not in closed set and (motion_cost, child_hash) not in open_set/frontier\n",
    "                #len?\n",
    "                if (child_hash_value not in closed_set)and (child_hash[1] not in [x[1] for x in open_set]): ##is child newly discovered? \n",
    "\n",
    "                    edges_dict[child_hash_value] = parent[1] #keep track of edges (ancestry) connections (new child tile) \n",
    "                    open_set_r, memoized_costs_r = self.update_frontier_memoize_child_cost(updated_agent, open_set, \n",
    "                    memoized_costs, new_child, motion_cost_set, move_option, parent_cost, manhatthan_dist)\n",
    "                    open_set = copy.deepcopy(open_set_r)\n",
    "                    memoized_costs = copy.deepcopy(memoized_costs_r)\n",
    "                    \n",
    "                elif child_hash in open_set:\n",
    "                    ##already discovered node\n",
    "                    incumbent = memoized_costs[child_hash_value]\n",
    "\n",
    "                    # cost of current child_hash < cost previous child\n",
    "                    if current_child_cost < incumbent:\n",
    "                        memoized_costs[child_hash_value] = current_child_cost #update cost of child from new parent\n",
    "                        edges_dict[child_hash_value] = parent[1] #forget previous ancestor\n",
    "                \n",
    "                move_option = move_option+1           \n",
    "\n",
    "\n",
    "        return (0, edges_dict, memoized_costs) #failed\n",
    "\n",
    "\n",
    "    ###\n",
    "    # update_frontier (open set)\n",
    "    # update memoize_child_cost (for current child node)\n",
    "    # \n",
    "    # input:\n",
    "    #       updated_agent: \n",
    "    #       open_set: list of node ((cost, g+h), (hash_of_node, hash_of_parent))\n",
    "    #       child: ((cost, g+h), (hash_of_node, hash_of_parent))\n",
    "    #       motion_cost_set: [int, int, int , int]\n",
    "    #       move_option: list of 1 to 4 char [\"U\", \"D\", \"L\", \"R\"]\n",
    "    #       parent_cost: current cumulative cost\n",
    "    #       parent: parent node\n",
    "    #       manhatthan_dist: int\n",
    "    #  output: \n",
    "    #       open_set: \n",
    "    #       g: (parent_retained_cost + move_cost_to_new_pos )\n",
    "    ####\n",
    "    def update_frontier_memoize_child_cost(self, updated_agent, open_set, memoized_costs, child_hash, motion_cost_set, move_option, parent_cost, manhatthan_dist):\n",
    "        current_child_cost = 0                   \n",
    "        move = updated_agent.get_moves_list()[move_option]\n",
    "        h = manhatthan_dist   \n",
    "        if move == \"U\": \n",
    "            g = motion_cost_set[0]+parent_cost\n",
    "            open_set.append((g+h , child_hash[1]))##add on priority queue \n",
    "            memoized_costs[child_hash[1]] = g #remember cost to that tile from current tile\n",
    "            current_child_cost = g\n",
    "        elif move == \"D\": \n",
    "            g = motion_cost_set[1]+parent_cost   \n",
    "            open_set.append((g+h , child_hash[1]))##add on priority queue \n",
    "            memoized_costs[child_hash[1]] = g #remember cost to that tile from current tile\n",
    "        elif move == \"L\":\n",
    "            g = motion_cost_set[2]+parent_cost \n",
    "            open_set.append((g+h , child_hash[1]))##add on priority queue\n",
    "            memoized_costs[child_hash[1]] = g #remember cost to that tile from current tile\n",
    "        elif move == \"R\":    \n",
    "            g = motion_cost_set[3]+parent_cost\n",
    "            open_set.append((g+h , child_hash[1]))##add on priority queue\n",
    "            memoized_costs[child_hash[1]] = g #remember cost to that tile from current tile\n",
    "\n",
    "        return open_set, memoized_costs\n",
    "            \n",
    "\n",
    "    ###\n",
    "    # calculate manhattahn distance between 2 points\n",
    "    # the use absolute value is less computationally expensive than using \n",
    "    # euclidian distance\n",
    "    #\n",
    "    # input:\n",
    "    #    current_point: start position [x,y]\n",
    "    #    goal_point:goal position [x,y]\n",
    "    #\n",
    "    # output:\n",
    "    #    dist: positive distance between start and goal\n",
    "    ###\n",
    "    def heuristic(self, current_point: List[int], goal_point: List[int]):\n",
    "        return abs(current_point[0]-goal_point[0])+abs(current_point[1]-goal_point[1])\n",
    "\n",
    "\n",
    "    ###\n",
    "    # reconstruct path from goal to answer by taking \n",
    "    # \n",
    "    # input:\n",
    "    #       ancestry \n",
    "    #       start_hash, \n",
    "    #       goal_hash, \n",
    "    #       env: environment.Environment, \n",
    "    #       agent\n",
    "    # output:\n",
    "    #       path_array: path_array[::-1]      \n",
    "    #       cost: final_cost\n",
    "    # ###\n",
    "    def reconstruct_path(self, ancestors_dict, start_hash, goal_hash, env: environment.Environment):\n",
    "        coord = self.find_tile_by_hash(env, goal_hash)\n",
    "        current_key = goal_hash\n",
    "        #path_string = str(coord)\n",
    "        path_array = []\n",
    "        path_array.append(coord)\n",
    "        cost = 0\n",
    "        print(\" visited  \", len(ancestors_dict[1]))\n",
    "        if(ancestors_dict[0]!= 0):#only reconstruct if we have found a path\n",
    "            cost = cost+ancestors_dict[2][current_key]\n",
    "            while current_key != start_hash:\n",
    "                new_key = ancestors_dict[1][current_key]\n",
    "                coord = self.find_tile_by_hash(env, new_key) \n",
    "                #path_string = path_string+\" , \"+str(coord)\n",
    "                path_array.append(coord)\n",
    "                current_key = new_key\n",
    "                \n",
    "        else:\n",
    "            print(\"ancestry cannot be found path was not reached\")\n",
    "               \n",
    "        return path_array[::-1], cost\n",
    "\n",
    "start_time = time.time()\n",
    "env = environment.Environment(7,7, [[1,1], [2,1], [2, 2], [3,3], [1,4]])\n",
    "\n",
    "A_Star = A_Star_Search()\n",
    "\n",
    "agent = agent.Agent([0,0], [2,4], [1,2,3,4])\n",
    "\n",
    "print(\"agent : start \", agent.initial_state, \" agent goal \", agent.goal_state)\n",
    "mat_size = env.get_matrix_dimension()[0]*env.get_matrix_dimension()[1]\n",
    "my_plt = env.draw_map(agent)\n",
    "goal = A_Star.fetch_Goal_Node(agent.get_initial_state_hash(), agent.get_goal_state_hash(), mat_size, env, agent)\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory usage \",process.memory_info().rss)  # in bytes \n",
    "print(\" peak m usage \", resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "print(\"total time \", time.time() - start_time)\n",
    "\n",
    "print(\"------------- ROBOT SIMULATED PATH A_Star GRAPH ------------------ \")\n",
    "path = A_Star.reconstruct_path(goal, agent.get_initial_state_hash(), agent.get_goal_state_hash(), env)\n",
    "print(path[0],\"\\n cost = \",path[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = [x[0] for x in  path[0]]\n",
    "y = [x[1] for x in  path[0]]\n",
    "my_plt.plot(y, x, linestyle='solid', c='red')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "agent : start  [0, 0]  agent goal  [2, 4]\n",
      "memory usage  96948224\n",
      " peak m usage  94676\n",
      "total time  0.061679840087890625\n",
      "------------- ROBOT SIMULATED PATH A_Star GRAPH ------------------ \n",
      " visited   23\n",
      "[[0, 0], [0, 1], [0, 2], [1, 2], [1, 3], [2, 3], [2, 4]] \n",
      " cost =  20\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f94eb3ee610>]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "44cce84d679a218813427bcac8c2748fdd526cfa74e0e6ea21b712c28e2cef91"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}